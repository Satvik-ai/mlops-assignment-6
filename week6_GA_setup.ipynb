{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Deploying Iris-detection model using Vertex AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: dvc in /opt/conda/lib/python3.10/site-packages (3.63.0)\n",
      "Requirement already satisfied: dvc-gs in /opt/conda/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (8.4.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (25.4.0)\n",
      "Requirement already satisfied: celery in /opt/conda/lib/python3.10/site-packages (from dvc) (5.5.3)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.4.6)\n",
      "Requirement already satisfied: configobj>=5.0.9 in /opt/conda/lib/python3.10/site-packages (from dvc) (5.0.9)\n",
      "Requirement already satisfied: distro>=1.3 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.9.0)\n",
      "Requirement already satisfied: dpath<3,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (2.2.0)\n",
      "Requirement already satisfied: dulwich in /opt/conda/lib/python3.10/site-packages (from dvc) (0.24.8)\n",
      "Requirement already satisfied: dvc-data<3.17,>=3.16.2 in /opt/conda/lib/python3.10/site-packages (from dvc) (3.16.12)\n",
      "Requirement already satisfied: dvc-http>=2.29.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (2.32.0)\n",
      "Requirement already satisfied: dvc-objects in /opt/conda/lib/python3.10/site-packages (from dvc) (5.1.2)\n",
      "Requirement already satisfied: dvc-render<2,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.0.2)\n",
      "Requirement already satisfied: dvc-studio-client<1,>=0.21 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.22.0)\n",
      "Requirement already satisfied: dvc-task<1,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.40.2)\n",
      "Requirement already satisfied: flatten_dict<1,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.4.2)\n",
      "Requirement already satisfied: flufl.lock<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (8.2.0)\n",
      "Requirement already satisfied: fsspec>=2024.2.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (2025.9.0)\n",
      "Requirement already satisfied: funcy>=1.14 in /opt/conda/lib/python3.10/site-packages (from dvc) (2.0)\n",
      "Requirement already satisfied: grandalf<1,>=0.7 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.8)\n",
      "Requirement already satisfied: gto<2,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.9.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.3.2)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.0.10)\n",
      "Requirement already satisfied: kombu in /opt/conda/lib/python3.10/site-packages (from dvc) (5.5.4)\n",
      "Requirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.10/site-packages (from dvc) (3.4.2)\n",
      "Requirement already satisfied: omegaconf in /opt/conda/lib/python3.10/site-packages (from dvc) (2.3.0)\n",
      "Requirement already satisfied: packaging>=19 in /opt/conda/lib/python3.10/site-packages (from dvc) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.10.3 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.12.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.1.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (4.3.8)\n",
      "Requirement already satisfied: psutil>=5.8 in /opt/conda/lib/python3.10/site-packages (from dvc) (5.9.3)\n",
      "Requirement already satisfied: pydot>=1.2.4 in /opt/conda/lib/python3.10/site-packages (from dvc) (4.0.1)\n",
      "Requirement already satisfied: pygtrie>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from dvc) (2.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /opt/conda/lib/python3.10/site-packages (from dvc) (3.2.5)\n",
      "Requirement already satisfied: requests>=2.22 in /opt/conda/lib/python3.10/site-packages (from dvc) (2.32.5)\n",
      "Requirement already satisfied: rich>=12 in /opt/conda/lib/python3.10/site-packages (from dvc) (13.9.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.11 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.18.15)\n",
      "Requirement already satisfied: scmrepo<4,>=3.5.2 in /opt/conda/lib/python3.10/site-packages (from dvc) (3.5.2)\n",
      "Requirement already satisfied: shortuuid>=0.5 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.0.13)\n",
      "Requirement already satisfied: shtab<2,>=1.3.4 in /opt/conda/lib/python3.10/site-packages (from dvc) (1.7.2)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.9.0)\n",
      "Requirement already satisfied: tomlkit>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.13.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.63.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (4.67.1)\n",
      "Requirement already satisfied: voluptuous>=0.11.7 in /opt/conda/lib/python3.10/site-packages (from dvc) (0.15.2)\n",
      "Requirement already satisfied: zc.lockfile>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from dvc) (4.0)\n",
      "Requirement already satisfied: dictdiffer>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc) (0.9.0)\n",
      "Requirement already satisfied: diskcache>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc) (5.6.3)\n",
      "Requirement already satisfied: sqltrie<1,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc) (0.11.2)\n",
      "Requirement already satisfied: orjson<4,>=3 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc) (3.11.4)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.1 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (4.2.2)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (5.1.0)\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (8.1.8)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (0.3.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (1.1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from celery->dvc) (2.9.0.post0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /opt/conda/lib/python3.10/site-packages (from flatten_dict<1,>=0.4.1->dvc) (1.17.0)\n",
      "Requirement already satisfied: atpublic in /opt/conda/lib/python3.10/site-packages (from flufl.lock<9,>=8.1.0->dvc) (5.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc) (0.4)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc) (2.12.0)\n",
      "Requirement already satisfied: pydantic-settings>=2 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc) (2.11.0)\n",
      "Requirement already satisfied: semver>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc) (3.0.4)\n",
      "Requirement already satisfied: typer>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc) (0.20.0)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in /opt/conda/lib/python3.10/site-packages (from kombu->dvc) (5.3.1)\n",
      "Requirement already satisfied: tzdata>=2025.2 in /opt/conda/lib/python3.10/site-packages (from kombu->dvc) (2025.2)\n",
      "Requirement already satisfied: gitpython>3 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc) (3.1.45)\n",
      "Requirement already satisfied: pygit2>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc) (1.18.2)\n",
      "Requirement already satisfied: asyncssh<3,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc) (2.21.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc) (2.9.1)\n",
      "Requirement already satisfied: cryptography>=39.0 in /opt/conda/lib/python3.10/site-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc) (46.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc) (4.15.0)\n",
      "Requirement already satisfied: gcsfs>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from dvc-gs) (2025.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1 in /opt/conda/lib/python3.10/site-packages (from pytest) (1.3.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /opt/conda/lib/python3.10/site-packages (from pytest) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from pytest) (2.19.2)\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest) (2.3.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (3.13.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /opt/conda/lib/python3.10/site-packages (from click-repl>=0.2.0->celery->dvc) (3.0.52)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cryptography>=39.0->asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=39.0->asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc) (2.22)\n",
      "Requirement already satisfied: urllib3>=2.2.2 in /opt/conda/lib/python3.10/site-packages (from dulwich->dvc) (2.5.0)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (5.2.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2.19.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->aiohttp-retry>=2.5.0->scmrepo<4,>=3.5.2->dvc) (3.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>3->scmrepo<4,>=3.5.2->dvc) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.5.2->dvc) (5.0.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (0.6.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.1->dvc) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf->dvc) (6.0.3)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from iterative-telemetry>=0.0.7->dvc) (1.4.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from iterative-telemetry>=0.0.7->dvc) (3.20.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc) (0.2.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->gto<2,>=1.6.0->dvc) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->gto<2,>=1.6.0->dvc) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->gto<2,>=1.6.0->dvc) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings>=2->gto<2,>=1.6.0->dvc) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22->dvc) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22->dvc) (2025.10.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12->dvc) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12->dvc) (0.1.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.11->dvc) (0.2.12)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc) (1.5.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from zc.lockfile>=1.2.1->dvc) (80.9.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs>=2022.11.0->dvc-gs) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2022.11.0->dvc-gs) (3.3.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.26.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.26.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform\n",
    "! pip3 install dvc dvc-gs pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GCS Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://iitmbs-mlops-21f1000344\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e95ca1e5e07c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
      "Initialized empty Git repository in /home/jupyter/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"chandrakarsatvik@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"Satvik Chandrakar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.dvcignore\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mapp/\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Actions for CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Required Secrets Keys\n",
    "- GCP_KEY_JSON\n",
    "- MLFLOW_TRACKING_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.github/’: File exists\n",
      "mkdir: cannot create directory ‘.github/workflows/’: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir .github/\n",
    "mkdir .github/workflows/\n",
    "touch .github/workflows/ci-dev.yml\n",
    "cat > .github/workflows/ci-dev.yml <<'EOF'\n",
    "name: CI - Dev Branch\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [dev]\n",
    "  pull_request:\n",
    "    branches: [dev, main]\n",
    "\n",
    "permissions:\n",
    "  contents: write\n",
    "  pull-requests: write\n",
    "\n",
    "jobs:\n",
    "  dev-ci:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout repository\n",
    "        uses: actions/checkout@v4\n",
    "        with:\n",
    "          fetch-depth: 0\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Configure DVC Remote\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_KEY_JSON }}\n",
    "        run: |\n",
    "          echo \"${GOOGLE_APPLICATION_CREDENTIALS}\" > gcp-key.json\n",
    "          dvc remote modify myremote credentialpath gcp-key.json\n",
    "\n",
    "      - name: Pull data from DVC\n",
    "        run: dvc pull -r myremote\n",
    "\n",
    "      - name: Fetch best model from MLflow\n",
    "        env:\n",
    "          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}\n",
    "        run: |\n",
    "          echo \"Fetching best model from MLflow experiment...\"\n",
    "          python <<'PYCODE'\n",
    "          import mlflow\n",
    "          from mlflow.tracking import MlflowClient\n",
    "          import os, shutil\n",
    "\n",
    "          client = MlflowClient()\n",
    "          experiment_name = \"Iris_DT_Classification-Exp\"\n",
    "          experiment = client.get_experiment_by_name(experiment_name)\n",
    "          if not experiment:\n",
    "              raise SystemExit(f\"Experiment '{experiment_name}' not found in MLflow.\")\n",
    "          \n",
    "          experiment_id = experiment.experiment_id\n",
    "          print(f\"Searching best model from experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "\n",
    "          results = mlflow.search_logged_models(\n",
    "              experiment_ids=[experiment_id],\n",
    "              order_by=[{\"field_name\": \"metrics.accuracy\", \"ascending\": False}],\n",
    "              max_results=1,\n",
    "              output_format=\"list\"\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              raise SystemExit(\"No logged models found in this experiment.\")\n",
    "\n",
    "          best_model = results[0]\n",
    "          print(f\"Best model ID: {best_model.model_id}\")\n",
    "          print(f\"Accuracy: {best_model.metrics[0].value}\")\n",
    "\n",
    "          model_uri = f\"models:/{best_model.model_id}\"\n",
    "          output_dir = \"fetched_model\"\n",
    "          if os.path.exists(output_dir):\n",
    "              shutil.rmtree(output_dir)\n",
    "\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "          print(f\"Saved best model locally at '{output_dir}/'\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Model sanity check & accuracy evaluation\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          import mlflow.pyfunc\n",
    "          import pandas as pd\n",
    "          from sklearn.model_selection import train_test_split\n",
    "          from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "          df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "          X = df.drop(columns=[\"species\"])\n",
    "          y = df[\"species\"]\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "          y_pred = model.predict(X_test)\n",
    "          acc = accuracy_score(y_test, y_pred)\n",
    "          report = classification_report(y_test, y_pred, output_dict=False)\n",
    "\n",
    "          print(f\"Test Accuracy: {acc:.4f}\")\n",
    "          print(report)\n",
    "\n",
    "          with open(\"accuracy_report.md\", \"w\") as f:\n",
    "              f.write(\"## Model Evaluation Report\\n\\n\")\n",
    "              f.write(f\"**Test Accuracy:** {acc:.4f}\\n\\n\")\n",
    "              f.write(\"### Sample Predictions:\\n\\n\")\n",
    "              sample_preds = pd.DataFrame({\"True\": y_test.values[:5], \"Predicted\": y_pred[:5]})\n",
    "              f.write(sample_preds.to_markdown(index=False))\n",
    "              f.write(\"\\n\\n```text\\n\")\n",
    "              f.write(\"### Classification Report\\n\\n\")\n",
    "              f.write(report)\n",
    "              f.write(\"\\n```\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Run unit tests and generate Markdown report\n",
    "        run: |\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --junitxml=report.xml > pytest_output.txt\n",
    "\n",
    "          echo \"## Dev Branch Pytest Summary Report\" > dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"**Date:** $(date)\" >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"### Test Results:\" >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          cat pytest_output.txt >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --cov=. --cov-report=term-missing >> pytest_output.txt 2>&1 || true\n",
    "\n",
    "      - name: Set up CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "        with:\n",
    "          version: latest\n",
    "          vega: true\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "\n",
    "      - name: Comment CML Report on commit (push)\n",
    "        if: github.event_name == 'push'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=commit --publish dev_report.md\n",
    "\n",
    "      - name: Comment CML Report on PR (pull request)\n",
    "        if: github.event_name == 'pull_request'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=pr --publish dev_report.md\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch .github/workflows/ci-main.yml\n",
    "cat > .github/workflows/ci-main.yml <<'EOF'\n",
    "name: CI - Main Branch\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "permissions:\n",
    "  contents: write\n",
    "  pull-requests: write\n",
    "\n",
    "jobs:\n",
    "  main-ci:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout repository\n",
    "        uses: actions/checkout@v4\n",
    "        with:\n",
    "          fetch-depth: 0\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Configure DVC Remote\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_KEY_JSON }}\n",
    "        run: |\n",
    "          echo \"${GOOGLE_APPLICATION_CREDENTIALS}\" > gcp-key.json\n",
    "          dvc remote modify myremote credentialpath gcp-key.json\n",
    "\n",
    "      - name: Pull data from DVC\n",
    "        run: dvc pull -r myremote\n",
    "\n",
    "      - name: Fetch best model from MLflow\n",
    "        env:\n",
    "          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}\n",
    "        run: |\n",
    "          echo \"Fetching best model from MLflow experiment...\"\n",
    "          python <<'PYCODE'\n",
    "          import mlflow\n",
    "          from mlflow.tracking import MlflowClient\n",
    "          import os, shutil\n",
    "\n",
    "          client = MlflowClient()\n",
    "          experiment_name = \"Iris_DT_Classification-Exp\"\n",
    "          experiment = client.get_experiment_by_name(experiment_name)\n",
    "          if not experiment:\n",
    "              raise SystemExit(f\"Experiment '{experiment_name}' not found in MLflow.\")\n",
    "          \n",
    "          experiment_id = experiment.experiment_id\n",
    "          print(f\"Searching best model from experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "\n",
    "          results = mlflow.search_logged_models(\n",
    "              experiment_ids=[experiment_id],\n",
    "              order_by=[{\"field_name\": \"metrics.accuracy\", \"ascending\": False}],\n",
    "              max_results=1,\n",
    "              output_format=\"list\"\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              raise SystemExit(\"No logged models found in this experiment.\")\n",
    "\n",
    "          best_model = results[0]\n",
    "          print(f\"Best model ID: {best_model.model_id}\")\n",
    "          print(f\"Accuracy: {best_model.metrics[0].value}\")\n",
    "\n",
    "          model_uri = f\"models:/{best_model.model_id}\"\n",
    "          output_dir = \"fetched_model\"\n",
    "          if os.path.exists(output_dir):\n",
    "              shutil.rmtree(output_dir)\n",
    "\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "          print(f\"Saved best model locally at '{output_dir}/'\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Evaluate model performance\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          import mlflow.pyfunc\n",
    "          import pandas as pd\n",
    "          from sklearn.model_selection import train_test_split\n",
    "          from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "          df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "          X = df.drop(columns=[\"species\"])\n",
    "          y = df[\"species\"]\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "          y_pred = model.predict(X_test)\n",
    "          acc = accuracy_score(y_test, y_pred)\n",
    "          report = classification_report(y_test, y_pred, output_dict=False)\n",
    "\n",
    "          print(f\"Test Accuracy: {acc:.4f}\")\n",
    "          print(report)\n",
    "\n",
    "          with open(\"accuracy_report.md\", \"w\") as f:\n",
    "              f.write(\"## Production Model Evaluation\\n\\n\")\n",
    "              f.write(f\"**Test Accuracy:** {acc:.4f}\\n\\n\")\n",
    "              f.write(\"### Sample Predictions:\\n\\n\")\n",
    "              sample_preds = pd.DataFrame({\"True\": y_test.values[:5], \"Predicted\": y_pred[:5]})\n",
    "              f.write(sample_preds.to_markdown(index=False))\n",
    "              f.write(\"\\n\\n```text\\n\")\n",
    "              f.write(\"### Classification Report\\n\\n\")\n",
    "              f.write(report)\n",
    "              f.write(\"\\n```\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Run tests and generate report\n",
    "        run: |\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --junitxml=report.xml > pytest_output.txt\n",
    "\n",
    "          echo \"## Main Branch PyTest Summary Report\" > main_report.md\n",
    "          echo \"\" >> main_report.md\n",
    "          echo \"**Date:** $(date)\" >> main_report.md\n",
    "          echo \"\" >> main_report.md\n",
    "          echo \"### Test Output\" >> main_report.md\n",
    "          echo '```' >> main_report.md\n",
    "          cat pytest_output.txt >> main_report.md\n",
    "          echo '```' >> main_report.md\n",
    "          echo \"\" >> main_report.md\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --cov=. --cov-report=term-missing >> pytest_output.txt 2>&1 || true\n",
    "\n",
    "      - name: Set up CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "        with:\n",
    "          version: latest\n",
    "          vega: true\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "\n",
    "      - name: Comment CML Report on commit (push)\n",
    "        if: github.event_name == 'push'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> main_report.md\n",
    "          cml comment create --target=commit --publish main_report.md\n",
    "\n",
    "      - name: Comment CML Report on PR (pull request)\n",
    "        if: github.event_name == 'pull_request'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> main_report.md\n",
    "          cml comment create --target=pr --publish main_report.md\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Actions for CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GCP_PROJECT_ID = iitmbs-mlops\n",
    "- GCP_REGION = us-central1\n",
    "- ARTIFACT_REPO = iris-repo\n",
    "- IMAGE_NAME = iris-fastapi\n",
    "- K8S_NAMESPACE = default\n",
    "- GKE_CLUSTER = iris-cluster\n",
    "- MLFLOW_TRACKING_URI\n",
    "- GCP_KEY_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch .github/workflows/cd.yml\n",
    "cat > .github/workflows/cd.yml <<'EOF'\n",
    "name: CD — Build & Deploy to GKE\n",
    "\n",
    "on:\n",
    "  workflow_run:\n",
    "    workflows: [\"CI - Main Branch\"]\n",
    "    branches: [main]\n",
    "    types:\n",
    "      - completed\n",
    "  workflow_dispatch:\n",
    "\n",
    "env:\n",
    "  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}\n",
    "  LOCATION: ${{ secrets.GCP_REGION }}\n",
    "  REPO: ${{ secrets.ARTIFACT_REPO }}\n",
    "  IMAGE_NAME: ${{ secrets.IMAGE_NAME }}\n",
    "  K8S_NAMESPACE: ${{ secrets.K8S_NAMESPACE }}\n",
    "\n",
    "jobs:\n",
    "  build-and-deploy:\n",
    "    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n",
    "    runs-on: ubuntu-latest\n",
    "    permissions:\n",
    "      contents: read\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout\n",
    "        uses: actions/checkout@v4\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies (MLflow)\n",
    "        run: |\n",
    "          python -m pip install --upgrade pip\n",
    "          pip install mlflow\n",
    "\n",
    "      - name: Fetch best model from MLflow\n",
    "        env:\n",
    "          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}\n",
    "        run: |\n",
    "          echo \"Fetching best model from MLflow experiment...\"\n",
    "          python <<'PYCODE'\n",
    "          import mlflow\n",
    "          from mlflow.tracking import MlflowClient\n",
    "          import os, shutil\n",
    "\n",
    "          client = MlflowClient()\n",
    "          experiment_name = \"Iris_DT_Classification-Exp\"\n",
    "          experiment = client.get_experiment_by_name(experiment_name)\n",
    "          if not experiment:\n",
    "              raise SystemExit(f\"Experiment '{experiment_name}' not found in MLflow.\")\n",
    "          \n",
    "          experiment_id = experiment.experiment_id\n",
    "          print(f\"Searching best model from experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "\n",
    "          results = mlflow.search_logged_models(\n",
    "              experiment_ids=[experiment_id],\n",
    "              order_by=[{\"field_name\": \"metrics.accuracy\", \"ascending\": False}],\n",
    "              max_results=1,\n",
    "              output_format=\"list\"\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              raise SystemExit(\"No logged models found in this experiment.\")\n",
    "\n",
    "          best_model = results[0]\n",
    "          print(f\"Best model ID: {best_model.model_id}\")\n",
    "          print(f\"Accuracy: {best_model.metrics[0].value}\")\n",
    "\n",
    "          model_uri = f\"models:/{best_model.model_id}\"\n",
    "          output_dir = \"app/models\"\n",
    "          if os.path.exists(output_dir):\n",
    "              shutil.rmtree(output_dir)\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "          print(f\"Downloading model from {model_uri}...\")\n",
    "          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "          print(f\"Saved best model to '{output_dir}/'\")\n",
    "          PYCODE\n",
    "          \n",
    "      - name: List downloaded model files\n",
    "        run: |\n",
    "          echo \"Contents of app/models directory:\"\n",
    "          ls -R app/models\n",
    "          \n",
    "      - name: Authenticate to GCP\n",
    "        uses: google-github-actions/auth@v2\n",
    "        with:\n",
    "          credentials_json: ${{ secrets.GCP_KEY_JSON }}\n",
    "\n",
    "      - name: Configure Docker for Artifact Registry\n",
    "        run: |\n",
    "          gcloud --quiet auth configure-docker ${LOCATION}-docker.pkg.dev\n",
    "\n",
    "      - name: Set image environment variables\n",
    "        run: |\n",
    "          IMAGE_TAG=${GITHUB_SHA::8}\n",
    "          echo \"IMAGE_TAG=${IMAGE_TAG}\" >> $GITHUB_ENV\n",
    "          IMAGE_FULL_NAME=${LOCATION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${IMAGE_TAG}\n",
    "          echo \"IMAGE_FULL_NAME=${IMAGE_FULL_NAME}\" >> $GITHUB_ENV\n",
    "          IMAGE_LATEST=${LOCATION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:latest\n",
    "          echo \"IMAGE_LATEST=${IMAGE_LATEST}\" >> $GITHUB_ENV\n",
    "\n",
    "      - name: Build and push Docker image\n",
    "        uses: docker/build-push-action@v5\n",
    "        with:\n",
    "          context: ./app\n",
    "          file: ./app/Dockerfile\n",
    "          push: true\n",
    "          tags: |\n",
    "            ${{ env.IMAGE_FULL_NAME }}\n",
    "            ${{ env.IMAGE_LATEST }}\n",
    "\n",
    "      - name: Get GKE credentials\n",
    "        uses: google-github-actions/get-gke-credentials@v2\n",
    "        with:\n",
    "          cluster_name: ${{ secrets.GKE_CLUSTER }}\n",
    "          location: ${{ secrets.GCP_REGION }}\n",
    "          project_id: ${{ secrets.GCP_PROJECT_ID }}\n",
    "\n",
    "      - name: Apply ConfigMap for FastAPI\n",
    "        env:\n",
    "          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}\n",
    "        run: |\n",
    "          echo \"Creating or updating ConfigMap 'iris-fastapi-config'...\"\n",
    "          kubectl create configmap iris-fastapi-config \\\n",
    "            --from-literal=MODEL_PATH=/app/models/model.joblib \\\n",
    "            --from-literal=ENV=production \\\n",
    "            --namespace ${K8S_NAMESPACE:-default} \\\n",
    "            --dry-run=client -o yaml | kubectl apply -f -\n",
    "\n",
    "      - name: Deploy to GKE\n",
    "        env:\n",
    "          IMAGE_FULL_NAME: ${{ env.IMAGE_FULL_NAME }}\n",
    "          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}\n",
    "        run: |\n",
    "          echo \"Deploying image ${IMAGE_FULL_NAME} to namespace ${K8S_NAMESPACE:-default}\"\n",
    "\n",
    "          # Apply manifests first (creates Deployment/Service if missing)\n",
    "          kubectl apply -f app/k8s/deployment.yaml --namespace ${K8S_NAMESPACE:-default}\n",
    "\n",
    "          # Update the image in the running deployment\n",
    "          kubectl set image deployment/iris-fastapi iris-fastapi=${IMAGE_FULL_NAME} --namespace ${K8S_NAMESPACE:-default}\n",
    "\n",
    "          # Wait for rollout completion\n",
    "          kubectl rollout status deployment/iris-fastapi --namespace ${K8S_NAMESPACE:-default} --timeout=300s\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCS as Remote Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'myremote' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d myremote {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote modify myremote credentialpath iitmbs-mlops-a99d6ce657ac.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Data with DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/iris.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/iris.csv |0.00 [00:00,     ?file/s\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/iris.csv to cache         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/iris.c0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 19.71file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/iris.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc add data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00,  134entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'iitmbs-mlops-21f1000344/files/md5'| |0/? [00:00<?,    ?f\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/3.77k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████|/home/jupyter/.dvc/cache/f3.77k/3.77k [00:00<00:00,    25.6kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to gs                     1/1 [00:00<00:00,  4.48file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup MLFlow Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SSH into the VM and run the following command to start MLFlow server\n",
    "# pip install mlflow\n",
    "# mlflow server --host 0.0.0.0 --port 8100 --allowed-hosts '*'  --cors-allowed-origins '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple Decision Tree model\n",
    "Build a Decision Tree model on iris data and log parameters, metrics, model, and artifacts to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/11/01 16:28:05 INFO mlflow.tracking.fluent: Experiment with name 'Iris_DT_Classification-Exp' does not exist. Creating a new experiment.\n",
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.933\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:28:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'IRIS-Classifier-dt'.\n",
      "2025/11/01 16:28:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 1\n",
      "Created version '1' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run kindly-fish-166 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/4d55fd2cdb3947dd9bb25aa6937983a0\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "Operation completed over 1 objects/3.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 4 --random_state 7 --version \"v1\" --stratify YES\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.967\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:28:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:28:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 2\n",
      "Created version '2' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run nimble-dolphin-805 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/491eca0589d544b1b636038544c53935\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.5 KiB/  2.5 KiB]                                                \n",
      "Operation completed over 1 objects/2.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 3 --random_state 7 --version \"v1\" --stratify YES\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.900\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:28:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:28:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 3\n",
      "Created version '3' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run vaunted-lynx-265 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/57f0816be09b4d019a4e4e5fc7db5c91\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.5 KiB/  2.5 KiB]                                                \n",
      "Operation completed over 1 objects/2.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 4 --random_state 7 --version \"v1\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.900\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:28:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:28:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 4\n",
      "Created version '4' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run welcoming-boar-775 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/b334ca2f09b2420aad9f00ca14488be4\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
      "Operation completed over 1 objects/2.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 3 --random_state 7 --version \"v1\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_data_validation.py \u001b[32m.\u001b[0m\u001b[32m                                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.48s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest tests/test_data_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_model_evaluation.py \u001b[32m.\u001b[0m\u001b[32m                                         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.24s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest tests/test_model_evaluation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to Git and Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\t\u001b[32mnew file:   .dvc/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   .dvc/config\u001b[m\n",
      "\t\u001b[32mnew file:   .dvcignore\u001b[m\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .dvc/config\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.github/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mapp/\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'dev'\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\t\u001b[32mnew file:   .dvc/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   .dvc/config\u001b[m\n",
      "\t\u001b[32mnew file:   .dvcignore\u001b[m\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .dvc/config\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.github/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mapp/\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git add app/ artifacts/ data/ src/ tests/ .dvc/ .github/ requirements.txt .gitconfig .dvcignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\t\u001b[32mnew file:   .dvc/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   .dvc/config\u001b[m\n",
      "\t\u001b[32mnew file:   .dvcignore\u001b[m\n",
      "\t\u001b[32mnew file:   .gitconfig\u001b[m\n",
      "\t\u001b[32mnew file:   .github/workflows/cd.yml\u001b[m\n",
      "\t\u001b[32mnew file:   .github/workflows/ci-dev.yml\u001b[m\n",
      "\t\u001b[32mnew file:   .github/workflows/ci-main.yml\u001b[m\n",
      "\t\u001b[32mnew file:   app/.ipynb_checkpoints/Dockerfile-checkpoint\u001b[m\n",
      "\t\u001b[32mnew file:   app/.ipynb_checkpoints/main-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   app/.ipynb_checkpoints/requirements-checkpoint.txt\u001b[m\n",
      "\t\u001b[32mnew file:   app/Dockerfile\u001b[m\n",
      "\t\u001b[32mnew file:   app/k8s/.ipynb_checkpoints/deployment-checkpoint.yaml\u001b[m\n",
      "\t\u001b[32mnew file:   app/k8s/deployment.yaml\u001b[m\n",
      "\t\u001b[32mnew file:   app/main.py\u001b[m\n",
      "\t\u001b[32mnew file:   app/requirements.txt\u001b[m\n",
      "\t\u001b[32mnew file:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[32mnew file:   data/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   data/iris.csv.dvc\u001b[m\n",
      "\t\u001b[32mnew file:   requirements.txt\u001b[m\n",
      "\t\u001b[32mnew file:   src/.ipynb_checkpoints/train-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/train.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/.ipynb_checkpoints/test_model_evaluation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mnew file:   tests/__pycache__/test_model_evaluation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mnew file:   tests/test_data_validation.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/test_model_evaluation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev (root-commit) 0d193be] Commit to both dev and main branch. First iteration done with 150 rows of iris data\n",
      " 27 files changed, 926 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n",
      " create mode 100644 .gitconfig\n",
      " create mode 100644 .github/workflows/cd.yml\n",
      " create mode 100644 .github/workflows/ci-dev.yml\n",
      " create mode 100644 .github/workflows/ci-main.yml\n",
      " create mode 100644 app/.ipynb_checkpoints/Dockerfile-checkpoint\n",
      " create mode 100644 app/.ipynb_checkpoints/main-checkpoint.py\n",
      " create mode 100644 app/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      " create mode 100644 app/Dockerfile\n",
      " create mode 100644 app/k8s/.ipynb_checkpoints/deployment-checkpoint.yaml\n",
      " create mode 100644 app/k8s/deployment.yaml\n",
      " create mode 100644 app/main.py\n",
      " create mode 100644 app/requirements.txt\n",
      " create mode 100644 artifacts/model.joblib\n",
      " create mode 100644 data/.gitignore\n",
      " create mode 100644 data/iris.csv.dvc\n",
      " create mode 100644 requirements.txt\n",
      " create mode 100644 src/.ipynb_checkpoints/train-checkpoint.py\n",
      " create mode 100644 src/train.py\n",
      " create mode 100644 tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\n",
      " create mode 100644 tests/.ipynb_checkpoints/test_model_evaluation-checkpoint.py\n",
      " create mode 100644 tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\n",
      " create mode 100644 tests/__pycache__/test_model_evaluation.cpython-310-pytest-8.4.2.pyc\n",
      " create mode 100644 tests/test_data_validation.py\n",
      " create mode 100644 tests/test_model_evaluation.py\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Commit to both dev and main branch. First iteration done with 150 rows of iris data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 0d193be29ae7c6cf8d5bdb6244d75039d7b899c0\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mdev\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Sat Nov 1 16:31:13 2025 +0000\n",
      "\n",
      "    Commit to both dev and main branch. First iteration done with 150 rows of iris data\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git remote add origin https://Satvik-ai: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@github.com/Satvik-ai/mlops-assignment-6.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 36, done.\n",
      "Counting objects: 100% (36/36), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (31/31), done.\n",
      "Writing objects: 100% (36/36), 11.70 KiB | 1.67 MiB/s, done.\n",
      "Total 36 (delta 1), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (1/1), done.\u001b[K\n",
      "To https://github.com/Satvik-ai/mlops-assignment-6.git\n",
      " * [new branch]      dev -> dev\n",
      "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'main'\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'main'\n"
     ]
    }
   ],
   "source": [
    "!git checkout main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 (delta 0), reused 0 (delta 0), pack-reused 0\n",
      "remote: \n",
      "remote: Create a pull request for 'main' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/Satvik-ai/mlops-assignment-6/pull/new/main\u001b[K\n",
      "remote: \n",
      "To https://github.com/Satvik-ai/mlops-assignment-6.git\n",
      " * [new branch]      main -> main\n",
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest Code Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the below given code to test_data_validation.py, push the pytest code changes to Dev branch and raise Pull Request to main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_numeric_values_positive():\n",
    "#     df = pd.read_csv(\"data/iris.csv\")\n",
    "#     numeric_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "#     # 4. Check all numeric values are positive\n",
    "#     for col in numeric_cols:\n",
    "#         assert (df[col] > 0).all(), f\"Negative or zero values found in {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_data_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.49s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Local test\n",
    "! pytest tests/test_data_validation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Version 2 of Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate augmentation by duplicating with noise\n",
    "augmented = data.copy()\n",
    "augmented[\"sepal_length\"] = augmented[\"sepal_length\"] + 0.1\n",
    "augmented[\"species\"] = augmented[\"species\"]\n",
    "\n",
    "# Merge\n",
    "data = pd.concat([data, augmented], ignore_index=True)\n",
    "\n",
    "# Save new version\n",
    "data.to_csv(\"data/iris.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "295           6.8          3.0           5.2          2.3  virginica\n",
       "296           6.4          2.5           5.0          1.9  virginica\n",
       "297           6.6          3.0           5.2          2.0  virginica\n",
       "298           6.3          3.4           5.4          2.3  virginica\n",
       "299           6.0          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Data Version 2 with DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/iris.csv |0.00 [00:00,     ?file/s\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/iris.csv to cache         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/iris.c0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 27.16file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/iris.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc add data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00,  152entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'iitmbs-mlops-21f1000344/files/md5'| |0/? [00:00<?,    ?f\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/8.27k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████|/home/jupyter/.dvc/cache/f8.27k/8.27k [00:00<00:00,    62.6kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to gs                     1/1 [00:00<00:00,  5.97file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with Data Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.983\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:43:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:43:09 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 5\n",
      "Created version '5' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run gaudy-gnat-847 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/dd7bf14e877f4c9e979d58e5ad62c4dd\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "Operation completed over 1 objects/3.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 4 --random_state 7 --version \"v2\" --stratify YES\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.967\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:43:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:43:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 6\n",
      "Created version '6' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run intelligent-ox-526 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/38caa7d8267444f5abfef0bede239da6\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.5 KiB/  2.5 KiB]                                                \n",
      "Operation completed over 1 objects/2.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 3 --random_state 7 --version \"v2\" --stratify YES\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.883\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:43:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:43:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 7\n",
      "Created version '7' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run persistent-loon-674 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/00a3452a9a394535aa540c3f1ae69430\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.7 KiB/  2.7 KiB]                                                \n",
      "Operation completed over 1 objects/2.7 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 4 --random_state 7 --version \"v2\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local data from data/iris.csv...\n",
      "Training Decision Tree model...\n",
      "Accuracy: 0.950\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/01 16:43:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'IRIS-Classifier-dt' already exists. Creating a new version of this model...\n",
      "2025/11/01 16:43:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IRIS-Classifier-dt, version 8\n",
      "Created version '8' of model 'IRIS-Classifier-dt'.\n",
      "Training and logging complete!\n",
      "🏃 View run persistent-skunk-132 at: http://127.0.0.1:8100/#/experiments/691612082528514903/runs/e17408d4160242389b04eae1b2761607\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/691612082528514903\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
      "Operation completed over 1 objects/2.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --max_depth 3 --random_state 7 --version \"v2\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to Git, Commit and Push to Dev Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tartifacts/model.joblib\n",
      "M\tdata/iris.csv.dvc\n",
      "M\ttests/.ipynb_checkpoints/test_data_validation-checkpoint.py\n",
      "M\ttests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\n",
      "M\ttests/test_data_validation.py\n",
      "Switched to branch 'dev'\n",
      "Your branch is up to date with 'origin/dev'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "Your branch is up to date with 'origin/dev'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[31mmodified:   data/iris.csv.dvc\u001b[m\n",
      "\t\u001b[31mmodified:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[31mmodified:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[31mmodified:   tests/test_data_validation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git add data/ tests/ artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "Your branch is up to date with 'origin/dev'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\t\u001b[32mmodified:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[32mmodified:   data/iris.csv.dvc\u001b[m\n",
      "\t\u001b[32mmodified:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mmodified:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mmodified:   tests/test_data_validation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31mweek6_GA_setup.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev 95bd8d8] Second commit to dev branch. Pytest coode changes and second iteration with 300 rows of iris data\n",
      " 5 files changed, 18 insertions(+), 4 deletions(-)\n",
      " rewrite tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc (61%)\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Second commit to dev branch. Pytest coode changes and second iteration with 300 rows of iris data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 95bd8d8c6faa3327c5f71ebc9ce7c13b58806e43\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mdev\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Sat Nov 1 16:44:30 2025 +0000\n",
      "\n",
      "    Second commit to dev branch. Pytest coode changes and second iteration with 300 rows of iris data\n",
      "\n",
      "\u001b[33mcommit 0d193be29ae7c6cf8d5bdb6244d75039d7b899c0\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/dev\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Sat Nov 1 16:31:13 2025 +0000\n",
      "\n",
      "    Commit to both dev and main branch. First iteration done with 150 rows of iris data\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 21, done.\n",
      "Counting objects: 100% (21/21), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (10/10), done.\n",
      "Writing objects: 100% (11/11), 1.99 KiB | 1018.00 KiB/s, done.\n",
      "Total 11 (delta 5), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/Satvik-ai/mlops-assignment-6.git\n",
      "   0d193be..95bd8d8  dev -> dev\n"
     ]
    }
   ],
   "source": [
    "!git push origin dev"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
